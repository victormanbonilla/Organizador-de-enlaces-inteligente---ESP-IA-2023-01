{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data.csv\")\n",
    "df.drop(['index'], inplace=True, axis=1)\n",
    "df.drop(['website_url'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_website_text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>official site good hotel accommodation big sav...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>expedia hotel book sites like use vacation wor...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tripadvisor hotel book sites like previously d...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cheap flights search compare flights momondo f...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bot create free account create free account si...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                cleaned_website_text Category\n",
       "0  official site good hotel accommodation big sav...   Travel\n",
       "1  expedia hotel book sites like use vacation wor...   Travel\n",
       "2  tripadvisor hotel book sites like previously d...   Travel\n",
       "3  cheap flights search compare flights momondo f...   Travel\n",
       "4  bot create free account create free account si...   Travel"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de categorías: 16\n"
     ]
    }
   ],
   "source": [
    "num_categories = df['Category'].nunique()\n",
    "print(\"Número de categorías:\", num_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Travel', 'Social Networking and Messaging', 'News',\n",
       "       'Streaming Services', 'Sports', 'Photography',\n",
       "       'Law and Government', 'Health and Fitness', 'Games', 'E-Commerce',\n",
       "       'Forums', 'Food', 'Education', 'Computers and Technology',\n",
       "       'Business/Corporate', 'Adult'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catg = list(df['Category'].unique())\n",
    "df['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Travel',\n",
       " 'Social Networking and Messaging',\n",
       " 'News',\n",
       " 'Streaming Services',\n",
       " 'Sports',\n",
       " 'Photography',\n",
       " 'Law and Government',\n",
       " 'Health and Fitness',\n",
       " 'Games',\n",
       " 'E-Commerce',\n",
       " 'Forums',\n",
       " 'Food',\n",
       " 'Education',\n",
       " 'Computers and Technology',\n",
       " 'Business/Corporate',\n",
       " 'Adult']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Travel\": 0,\n",
      "\"Social Networking and Messaging\": 1,\n",
      "\"News\": 2,\n",
      "\"Streaming Services\": 3,\n",
      "\"Sports\": 4,\n",
      "\"Photography\": 5,\n",
      "\"Law and Government\": 6,\n",
      "\"Health and Fitness\": 7,\n",
      "\"Games\": 8,\n",
      "\"E-Commerce\": 9,\n",
      "\"Forums\": 10,\n",
      "\"Food\": 11,\n",
      "\"Education\": 12,\n",
      "\"Computers and Technology\": 13,\n",
      "\"Business/Corporate\": 14,\n",
      "\"Adult\": 15,\n"
     ]
    }
   ],
   "source": [
    "for index, i in enumerate(catg):\n",
    "    print(f'\"{i}\": {index},')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_num = {\n",
    "    \"Travel\": 0,\n",
    "    \"Social Networking and Messaging\": 1,\n",
    "    \"News\": 2,\n",
    "    \"Streaming Services\": 3,\n",
    "    \"Sports\": 4,\n",
    "    \"Photography\": 5,\n",
    "    \"Law and Government\": 6,\n",
    "    \"Health and Fitness\": 7,\n",
    "    \"Games\": 8,\n",
    "    \"E-Commerce\": 9,\n",
    "    \"Forums\": 10,\n",
    "    \"Food\": 11,\n",
    "    \"Education\": 12,\n",
    "    \"Computers and Technology\": 13,\n",
    "    \"Business/Corporate\": 14,\n",
    "    \"Adult\": 15,\n",
    "}\n",
    "\n",
    "\n",
    "df.replace({'Category': category_num}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_website_text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>official site good hotel accommodation big sav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>expedia hotel book sites like use vacation wor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tripadvisor hotel book sites like previously d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cheap flights search compare flights momondo f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bot create free account create free account si...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>old nude women porn mature granny sex horny ol...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>bdsm cams bdsm chat bondage cams free bdsm vid...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>porno dvd online european porn dvd cheap adult...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>anal dream house anal dream house anal dream h...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>world sex news daily sex news adult news eroti...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1408 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   cleaned_website_text  Category\n",
       "0     official site good hotel accommodation big sav...         0\n",
       "1     expedia hotel book sites like use vacation wor...         0\n",
       "2     tripadvisor hotel book sites like previously d...         0\n",
       "3     cheap flights search compare flights momondo f...         0\n",
       "4     bot create free account create free account si...         0\n",
       "...                                                 ...       ...\n",
       "1403  old nude women porn mature granny sex horny ol...        15\n",
       "1404  bdsm cams bdsm chat bondage cams free bdsm vid...        15\n",
       "1405  porno dvd online european porn dvd cheap adult...        15\n",
       "1406  anal dream house anal dream house anal dream h...        15\n",
       "1407  world sex news daily sex news adult news eroti...        15\n",
       "\n",
       "[1408 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Entradas = df.iloc[:, 0].values\n",
    "Salida = y = df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "promedio de las longitudes: 5274.671164772727\n"
     ]
    }
   ],
   "source": [
    "longitudes = df['cleaned_website_text'].str.len()\n",
    "\n",
    "# Calcular el promedio de las longitudes\n",
    "promedio = longitudes.mean()\n",
    "\n",
    "print('promedio de las longitudes:', promedio)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords', quiet=True)\n",
    "# nltk.download('punkt', quiet=True)\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import seaborn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import model_selection as ms\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1408, 60031)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = feature_extraction.text.CountVectorizer()\n",
    "extractor = counts.fit(Entradas)\n",
    "X = counts.fit_transform(Entradas)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = ms.train_test_split(X, Salida, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_naive = naive_bayes.MultinomialNB()\n",
    "model_naive.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9822380106571936"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_naive.score(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('feature_extractor.pkl', 'wb') as archivo:\n",
    "    pickle.dump(extractor, archivo)\n",
    "\n",
    "with open('model_naive.pkl', 'wb') as archivo:\n",
    "    pickle.dump(model_naive, archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
